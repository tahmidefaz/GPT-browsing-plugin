{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM8OsWcsHyqQiZV8VYmHtSL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tahmidefaz/GPT-browsing-plugin/blob/main/notebooks/GPT_browsing_plugin_v1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GPT Browsing Pluging\n",
        "\n",
        "### A browsing plugin for Huggingface based chat LLM models"
      ],
      "metadata": {
        "id": "52_kTaQ478ls"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jf1vBzdJdNWL",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Install Dependencies\n",
        "\n",
        "!pip install accelerate>=0.12.0 transformers[torch]==4.25.1\n",
        "!pip install newspaper3k\n",
        "!pip install wikipedia"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Download Language Model\n",
        "#@markdown > *Loading the smallest Dolly 2.0 model (3B) by default. I found it very capable with the browsing plugin.\n",
        "#@markdown I was not able to try out other similar models because of GPU memory restrictions.*\n",
        "\n",
        "import torch\n",
        "from transformers import pipeline\n",
        "\n",
        "language_model = \"databricks/dolly-v2-3b\" #@param{type: 'string'}\n",
        "generate_text = pipeline(model=language_model, torch_dtype=torch.bfloat16, trust_remote_code=True, device_map=\"auto\")\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "UuNQP5MWdUxL"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Setup Search Engine\n",
        "#@markdown ##### Setting up the search engine and the page scrapers here\n",
        "\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "import requests\n",
        "from newspaper import Article\n",
        "\n",
        "def search_ddg(query):\n",
        "    url = 'https://duckduckgo.com/html/'\n",
        "    params = {\n",
        "        'q': query,\n",
        "        's': '0',\n",
        "        'nextParams': '',\n",
        "        'v': 'l',\n",
        "        'o': 'json',\n",
        "        'dc': 'us-en'\n",
        "    }\n",
        "    headers = {\n",
        "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
        "    res = requests.get(url, params=params, headers=headers)\n",
        "    soup = BeautifulSoup(res.text, 'html.parser')\n",
        "    results = []\n",
        "    for result in soup.select('div.result'):\n",
        "        title = result.select_one('.result__title').text\n",
        "        url = result.select_one('a.result__url')['href']\n",
        "        snippet = result.select_one('.result__snippet').text\n",
        "        results.append({'title': title, 'url': url, 'snippet': snippet})\n",
        "    return results\n",
        "\n",
        "def read_page(url):\n",
        "  try:\n",
        "    print('Reading page')\n",
        "    article = Article(url)\n",
        "    article.download()\n",
        "    article.parse()\n",
        "    return article.text[:2000]\n",
        "  except Exception as e:\n",
        "    print(\"exception reading page:\", e)\n",
        "    return ''\n",
        "\n",
        "# results = search_ddg('fusion breakthrough')\n",
        "# for result in results[:3]:\n",
        "#     print(result['title'])\n",
        "#     # print(result['url'])\n",
        "#     print(result['snippet'])\n",
        "#     print()\n",
        "\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "iLvRjxNDhnZn"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Browsing Parameters Explanation\n",
        "`search_topic` - The search topic. This is different from the user questions. This can be things like \"Trappist-1 planets\", \"SVB collapse\" etc.\n",
        "\n",
        "`show_search_results` - When checked, prints out the parsed content that is passed to the LLM.\n",
        "\n",
        "`snippets_to_use` - The number of search snippets to use for content when `open_links` is uncheked. The model seems to find the snippets very useful for answering questions.\n",
        "\n",
        "`open_links` - Whether or not to click on search engine results and scrape content from the different pages.\n",
        "\n",
        "`links_to_open` - The number of pages to click through for content when `open_links` is checked.\n",
        "\n",
        "`max_page_chars` - Contents approximately greater then this number is truncated. Large numbers may not fit in the GPU, and might make LLM response slower.\n",
        "\n",
        "`use_wikipedia` - Only uses Wikipedia for the `search_topic` when checked.\n",
        "\n",
        "`max_wiki_article_chars` - Similar to `max_page_chars`, but for Wikipedia articles."
      ],
      "metadata": {
        "id": "lgQKpuemTW-e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Fetch Search Results\n",
        "\n",
        "#@markdown ###**Parameters**\n",
        "search_results = '<<Search Results>>\\n\\n'\n",
        "\n",
        "search_topic = 'Marty McFly' #@param{type: 'string'}\n",
        "\n",
        "show_search_results = False #@param{type: 'boolean'}\n",
        "\n",
        "#@markdown ### Search Engine options\n",
        "snippets_to_use = 5 #@param{type: 'number'}\n",
        "\n",
        "open_links = True #@param{type: 'boolean'}\n",
        "links_to_open = 2 #@param{type: 'number'}\n",
        "max_page_chars = 1800 #@param{type: 'number'}\n",
        "\n",
        "#@markdown ### Wikipedia options\n",
        "use_wikipedia = False #@param{type: 'boolean'}\n",
        "max_wiki_article_chars = 2000 #@param{type: 'number'}\n",
        "\n",
        "if use_wikipedia:\n",
        "  import wikipedia\n",
        "  from wikipedia.exceptions import DisambiguationError, PageError\n",
        "\n",
        "  try:\n",
        "    # Get a WikipediaPage object for a page\n",
        "    page = wikipedia.page(search_topic)\n",
        "\n",
        "    search_results += f'{page.title}\\n{page.content}'\n",
        "    search_results = search_results[:max_wiki_article_chars]\n",
        "    print(f\"Read Wikipedia article titled: {page.title}\")\n",
        "  except DisambiguationError as e:\n",
        "      # Handle disambiguation pages\n",
        "      print(e.options)\n",
        "  except PageError as e:\n",
        "      # Handle page not found errors\n",
        "      print(e)\n",
        "else:\n",
        "  results = search_ddg(search_topic)\n",
        "  if open_links:\n",
        "    target_content_length = max_page_chars // links_to_open\n",
        "    i = 0\n",
        "    opened_pages = 0\n",
        "    while opened_pages < links_to_open and i < len(results):\n",
        "      page_title = results[i]['title']\n",
        "      search_snippet = results[i]['snippet']\n",
        "      print(\"Clicked on:\", page_title)\n",
        "      page_content = read_page(results[i]['url'])\n",
        "      print(\"Finished reading page\")\n",
        "      i += 1\n",
        "      if len(page_content) < target_content_length:\n",
        "        print(\"not enough content in page, skipping...\\n\")\n",
        "        continue\n",
        "      print(\"\\n\")\n",
        "      search_results += f'{opened_pages+1}. [TITLE]{page_title} [PAGE CONTENT] {page_content[:target_content_length]}\\n'\n",
        "\n",
        "      opened_pages += 1\n",
        "  else:\n",
        "    for i, result in enumerate(results[:snippets_to_use]):\n",
        "        title = result['title']\n",
        "        snippet = result['snippet']\n",
        "        search_results += f'{i+1}. [TITLE]{title}[SNIPPET] {snippet}\\n'\n",
        "    print(f\"Read {snippets_to_use} search engine snippets.\")\n",
        "\n",
        "if show_search_results:\n",
        "  print(\"Search Result/Article length:\", len(search_results))\n",
        "  print(search_results)\n",
        "\n",
        "chat_log = []"
      ],
      "metadata": {
        "cellView": "form",
        "id": "OYcAx6GSdcb2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d5ae2e3-1d4a-4a06-842b-8aa29af20b48"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Clicked on: \n",
            "Marty McFly - Wikipedia\n",
            "\n",
            "Reading page\n",
            "Finished reading page\n",
            "\n",
            "\n",
            "Clicked on: \n",
            "Back to the Future (1985) - Michael J. Fox as Marty McFly - IMDb\n",
            "\n",
            "Reading page\n",
            "Finished reading page\n",
            "not enough content in page, skipping...\n",
            "\n",
            "Clicked on: \n",
            "Michael J. Fox - Wikipedia\n",
            "\n",
            "Reading page\n",
            "Finished reading page\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Ask Questions\n",
        "\n",
        "system_str = \"<<SYSTEM>>\\nYou are a search assistant that reads the returned search results and your own knowledge to answer the user queries. If you use the search result, make sure to reference it using a superscript. Like ^2, ^3, ^1 etc.\"\n",
        "user_query = \"Who is Marty McFly?\" #@param{type: 'string'}\n",
        "\n",
        "chat_history = ''\n",
        "for i, chat in enumerate(chat_log):\n",
        "  if (i+1)%2 != 0:\n",
        "    chat_history += f'<<User>>\\n{chat}\\n'\n",
        "  else:\n",
        "    chat_history += f'<<Assistant>>\\n{chat}\\n'\n",
        "\n",
        "prompt = f\"{system_str}\\n\\n{search_results}\\n\\n{chat_history}<<User>>\\n{user_query}\"\n",
        "# print(prompt)\n",
        "\n",
        "res = generate_text(prompt)\n",
        "assistant_output = res[0][\"generated_text\"]\n",
        "\n",
        "chat_log.append(user_query)\n",
        "chat_log.append(assistant_output)\n",
        "\n",
        "for i, chat in enumerate(chat_log):\n",
        "  if (i+1)%2 != 0:\n",
        "    print(f\"[USER]\\n{chat}\\n\")\n",
        "  else:\n",
        "    print(f\"[ASSISTANT]\\n{chat}\\n\")\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "vmUqxtUVghav"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}